{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x7GW3-8hY6f"
      },
      "source": [
        "# Homework 2\n",
        "## IDS 576 <br>\n",
        "Name: Isaac Salvador <br>\n",
        "Email: isalva2@uic.edu <br>\n",
        "UIN: 6669845132 <br>\n",
        "\n",
        "Name: Ahreum Kim <br>\n",
        "Email: akim239@uic.edu <br>\n",
        "UIN: 653241895 <br>\n",
        "\n",
        "Name: Sadjad Bazarnovi <br>\n",
        "Email: sbazar3@uic.edu <br>\n",
        "UIN: 679314994 <br>\n",
        "\n",
        "please add your information here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGxRbbwUhY6j"
      },
      "source": [
        "## 1. CNNs and finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwvGv3LJhY6j"
      },
      "source": [
        "### Download the CIFAR 10 dataset (original data can be found [here](http://www.cs.toronto.edu/~kriz/cifar.html), and here is a link to the  pickled [python version](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz).)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "First we specify some data augmentations with [Transforms V2](https://pytorch.org/vision/stable/auto_examples/plot_transforms_v2.html) for both the training and testing sets. The following transforms are applied to the `train_transform` object:\n",
        "\n",
        "- `RandomRotation`: Rotates the image between 0 and 30 degrees\n",
        "  \n",
        "- `RandomHorizontalFlip`: Randomly flips an image along the horizontal axis\n",
        "  \n",
        "- `ToImageTensor`: transforms input image into a `torch.Tensor`\n",
        "  \n",
        "- `ConvertImageDtype`: converts elements in tensors to `float32` dtype â€“ necessary for development on M-series MacBooks.\n",
        "  \n",
        "- `Normalize`: Normalize tensor values such that the mean and standard deviation of the images become `0.0` and `1.0` respectively. Per-color mean and standard deviation values were calculated w.r.t. this [guide](https://saturncloud.io/blog/how-to-normalize-pytorch-cifar10-images-for-improved-model-performance/).\n",
        "\n",
        "We instantiate an `unaugmented_transform` object as well to create test and validation validation datasets without any augmentations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import mps\n",
        "import torchvision\n",
        "torchvision.disable_beta_transforms_warning()\n",
        "import torchvision.transforms.v2 as transforms\n",
        "\n",
        "# make torch deterministic for reproducibility\n",
        "torch.manual_seed(576)\n",
        "\n",
        "# set device\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available else \"cpu\")\n",
        "\n",
        "# previously calculated normalization values\n",
        "mean = [0.4934569299, 0.483376652, 0.4471793473]\n",
        "std = [0.2476211786, 0.2445851415, 0.2626110017]\n",
        "\n",
        "train_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToImageTensor(),\n",
        "        transforms.ConvertImageDtype(torch.float32),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]\n",
        ")\n",
        "\n",
        "unaugmented_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToImageTensor(),\n",
        "        transforms.ConvertImageDtype(torch.float32),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We next download the [CIFAR 10 Dataset](https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html) from the pytorch website and apply the transforms. The `unaugumented_set` is 50/50 split into a `test_set` and `val_set` using the `random_split` utility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "train_set = datasets.CIFAR10(\"./Misc_files/data\", train=True, transform=train_transform, download=True)\n",
        "\n",
        "unaugmented_set = datasets.CIFAR10(\"./Misc_files/data\", train=False, transform=unaugmented_transform, download=True)\n",
        "\n",
        "test_set, val_set = random_split(unaugmented_set, [0.5, 0.5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The train, test, and validation sets are then passed to a `Dataloader` iterable with a common practice `batch_size` of 32:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size = 64, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size = 64, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size = 64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the datasets finalized we can additionally view some sample instances of the data. Plotting instances of the training set can additionally show the results of of the data augmentations (`RandomRotation` is apparent)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size': 5})\n",
        "\n",
        "CIFAR10_labels = {\n",
        "    0: 'Airplane',\n",
        "    1: 'Automobile',\n",
        "    2: 'Bird',\n",
        "    3: 'Cat',\n",
        "    4: 'Deer',\n",
        "    5: 'Dog',\n",
        "    6: 'Frog',\n",
        "    7: 'Horse',\n",
        "    8: 'Ship',\n",
        "    9: 'Truck'\n",
        "}\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "# Define plot size and DPI\n",
        "fig = plt.figure(figsize=(8, 8), dpi=100)\n",
        "\n",
        "# Adjust space between subplots\n",
        "plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1, wspace=0.2, hspace=0.4)\n",
        "\n",
        "for i in range(16):\n",
        "    ax = fig.add_subplot(4, 4, i+1)\n",
        "    ax.set_title(CIFAR10_labels.get(int(labels[i])))\n",
        "    img = images[i].numpy().transpose((1, 2, 0))\n",
        "    img = std * img + mean\n",
        "    img = np.clip(img, 0, 1.)\n",
        "    plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wU_qcbLhY6k"
      },
      "source": [
        "### Use the pretrained Resnet18 model (from trochvision) to extract features. Use the features as inputs in a new multi-class logistic regression model (use nn.Linear/ nn.Module to define your model)\n",
        "- (a) Describe any choices made and report test performance.\n",
        "- (b) Display the top 5 correct predictions and the top 5 incorrect predictions in each class (show the images and the prediction labels) compactly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From torch's website, we can download [ResNet18](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html#torchvision.models.ResNet18_Weights) and it's associated default weights for implementation. The package `torchsummary` is used to obtain a `keras`-like summary of the model's architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# load ResNet18 and pretrained weights\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "import torch.nn as nn\n",
        "\n",
        "# create transfer learning model\n",
        "resnet18_based = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "\n",
        "'''\n",
        "# Freeze all layers except the last one\n",
        "for name, param in resnet18_based.named_parameters():\n",
        "    if name != 'classifier.weight' and name != 'classifier.bias':\n",
        "        param.requires_grad = False\n",
        "'''        \n",
        "\n",
        "new_classifier = nn.Sequential(\n",
        "    nn.ReLU(1000),\n",
        "    nn.Linear(1000, 10),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "\n",
        "resnet18_based.classifier = new_classifier\n",
        "\n",
        "'''\n",
        "# Unfreeze the last layer\n",
        "for param in resnet18_based.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "'''\n",
        "\n",
        "# use torch summary to obtain a keras-like summary of model architecture\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(resnet18_based, (3, 32, 32), verbose = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "for name, param in resnet18_based.named_parameters():\n",
        "    print(name, param.requires_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# model hyper parameters\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#optimizer = optim.Adam(resnet18_tl.parameters(), lr = 1e-3)\n",
        "optimizer = optim.Adam(resnet18_based.parameters(), lr=1e-3)\n",
        "\n",
        "resnet18_based.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define a function to compute accuracy\n",
        "def calculate_accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    accuracy = correct / labels.size(0)\n",
        "    return accuracy\n",
        "\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader = None, num_epochs=25):\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        train_loss = 0\n",
        "        total_accuracy = 0\n",
        "        \n",
        "        # Iterate over data.\n",
        "        for i, data in enumerate(tqdm(train_loader)):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)        \n",
        "\n",
        "            #loss.requires_grad = True\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            \n",
        "            # Calculate accuracy for this batch and accumulate\n",
        "            batch_accuracy = calculate_accuracy(outputs, labels)\n",
        "            total_accuracy += batch_accuracy\n",
        "\n",
        "        # validation on epoch\n",
        "        if val_loader != None:\n",
        "            \n",
        "            val_loss = 0\n",
        "            val_accuracy = 0\n",
        "            \n",
        "            model.eval()\n",
        "    \n",
        "            for i, data in enumerate(tqdm(val_loader)):\n",
        "                inputs, labels = data\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    outputs = model(inputs)\n",
        "                    val_loss = criterion(outputs, labels)\n",
        "                \n",
        "                val_loss += val_loss.item() * inputs.size(0)\n",
        "                \n",
        "                val_batch_accuracy = calculate_accuracy(outputs, labels)\n",
        "                val_accuracy += val_batch_accuracy\n",
        "\n",
        "        # Calculate average accuracy for the epoch\n",
        "        epoch_accuracy = total_accuracy / len(train_loader)\n",
        "        \n",
        "        \n",
        "        print('Train Loss: {:.4f} Train Accuracy: {:.4f}'.format(\n",
        "            train_loss / len(train_loader.dataset), epoch_accuracy))\n",
        "        \n",
        "        if val_loader != None:\n",
        "            \n",
        "            epoch_val_accuracy = val_accuracy / len(val_loader)\n",
        "            \n",
        "            print('Validation Loss: {:.4f} Validation Accuracy: {:.4f}'.format(\n",
        "                val_loss / len(val_loader.dataset), epoch_val_accuracy))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_model(resnet18_based, criterion, optimizer, train_loader, val_loader, num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# this is a test to extract features then train on logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "# create custom dataset that inherits torch Dataset class\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feature_data = self.features[idx]\n",
        "        label_data = self.labels[idx]\n",
        "        return feature_data, label_data\n",
        "\n",
        "# create new dataset from extracted features\n",
        "def create_new_dataset(model, dataloader):\n",
        "    \n",
        "    model.to(device)\n",
        "    \n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    \n",
        "    \n",
        "    \n",
        "    feature_list = []\n",
        "    label_list = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(dataloader):\n",
        "            inputs = inputs.to(device)  # Move inputs to the appropriate device\n",
        "            features = model(inputs)    # Get model features\n",
        "\n",
        "            feature_list.append(features.cpu())  # Move features back to CPU and store\n",
        "            label_list.append(labels)            # Store the original labels\n",
        "\n",
        "    # Concatenate the features and label data tensors\n",
        "    features_data = torch.cat(feature_list, dim=0)\n",
        "    labels_data = torch.cat(label_list, dim=0)\n",
        "\n",
        "    # Create a new dataset using the obtained features and original labels\n",
        "    new_dataset = MyDataset(features_data, labels_data)\n",
        "\n",
        "    return new_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dataset = create_new_dataset(resnet18(weights=ResNet18_Weights.DEFAULT), train_loader)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_classifier = nn.Sequential(\n",
        "    nn.ReLU(1000),\n",
        "    nn.Linear(1000, 10),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "\n",
        "# model hyper parameters\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#optimizer = optim.Adam(resnet18_tl.parameters(), lr = 1e-3)\n",
        "optimizer = optim.Adam(new_classifier.parameters(), lr=1e-3)\n",
        "\n",
        "new_classifier.to(device)\n",
        "\n",
        "for name, param in new_classifier.named_parameters():\n",
        "    print(name, param.requires_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_model(new_classifier, criterion, optimizer, test_loader, num_epochs=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AGGqFLJhY6k"
      },
      "source": [
        "Finetune the Resnet18 model's parameters suitably and repeat parts (a) and (b) from above. Compare the performance of finetuning versus using extracted features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb6cxHDihY6k"
      },
      "source": [
        "## 2. Movie embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owxHN_auhY6l"
      },
      "source": [
        "\n",
        "Instead of embedding words, we will embed movies.  In particular, if we can embed movies, then similar movies will be close to each other and can be recommended.  This line of reasoning  is analogous to the [distributional hypothesis of word meanings](https://en.wikipedia.org/wiki/Distributional_semantics). For words, this roughly translates to words that appear in similar sentences should have similar vector representations. For movies, vectors for two movies should be similar if they are watched by similar people.\n",
        "\n",
        "Let the total number of movies be $M$. Let $X_{i,j}$ be the number of users that liked both movies $i$ and $j$. We want to obtain vectors $v_1,...,v_i,...,v_j,...,v_M$ for all movies such that we minimize the cost $c(v_1,...,v_M) = \\sum_{i=1}^{M}\\sum_{j=1}^{M}\\mathbf{1}_{[i\\neq j]}(v_i^Tv_j - X_{i,j})^2$. Here $\\mathbf{1}_{[i\\neq j]}$ is a function that is $0$ when $i=j$ and $1$ otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dkJNBx6hY6l"
      },
      "source": [
        "Compute data $X_{i,j}$ from the movielens (small) [dataset](https://files.grouplens.org/datasets/movielens/ml-latest-small.zip). You can also download using the link to `ml-latest-small.zip` from this [page](https://grouplens.org/datasets/movielens/) (be sure to read the corresponding [description](https://files.grouplens.org/datasets/movielens/ml-latest-small-README.html)). Briefly describe your data prep workflow (you can use `pandas` if needed)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN6ezzJ6hY6l"
      },
      "source": [
        "Optimize function $c(v_1,...,v_M)$ over $v_1,...,v_M$ using gradient descent (using `pytorch` or `tensorflow`). Plot the loss as a function of iteration for various choices (learning rates, choice of optimizers etc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PrfHenBhY6m"
      },
      "source": [
        "Recommend top 10 movies (not vectors or indices but movie names) given movies (a) _Apollo 13_, (b) _Toy Story_, and (c) _Home Alone_ . Describe your recommendation strategy. Do the recommendations change when you change learning rates or optimizers? Why or why not?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(\"this is isaac's test\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
