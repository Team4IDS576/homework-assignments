{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n13hAAC2wmgC"
      },
      "source": [
        "# 1. RNN for Language Modeling (4pt)\n",
        "\n",
        " -  Import the torchtext IMDB dataset and do the following:\n",
        "   -  Build a  Markov (n-gram) language model.\n",
        "   -  Change the output and the model appropriately in _[Simple Sentiment Analysis.ipynb](https://github.com/bentrevett/pytorch-sentiment-analysis)_ (also available [here](https://github.com/thejat/dl-notebooks/blob/master/examples/rnn/Seq2Seq_RNN_Simple_Sentiment_Analysis.ipynb) where the imports have been slightly modified) to build an LSTM based language model. Plot the training performance as a function of epochs/iterations.\n",
        " -  For each model, describe the key design choices made. Briefly mention how each choice influences training time and generative quality.\n",
        " -  For each model, starting with the phrase \"My favorite movie \", sample the next few words and create an approx. 20 word generated review. Repeat this 5 times (you should ideally get different outputs each time) and report the outputs.\n",
        " - Note: make any assumptions as necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjlnd8E4wmgF"
      },
      "source": [
        "## `torchtext` IMDB dataset\n",
        "We begin by setting up the `torch` environment and downloading the `IMDB` dataset from the `torchtext.data.Dataset` class. The `torchtext` dataset is preprocessed into a into a collection of lists of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L_KGaQzwmgG",
        "outputId": "b566d058-d0ab-4754-f25a-413768ed3106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import mps\n",
        "\n",
        "import torchtext\n",
        "from torchtext import datasets\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "\n",
        "# make torch deterministic for reproducibility\n",
        "seed = 576\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# set device\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Torch Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "S7R1JasZwmgG",
        "outputId": "30c39aa2-b1a9-4e60-d486-24bb7d98e3e9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-224-21f3729919e4>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mlowercase_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcleaned_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[^A-Za-z0-9\\s]+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowercase_review\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<br />'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtokenized_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_review\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# train model on training split\n",
        "train_iter = datasets.IMDB(split=\"train\")\n",
        "\n",
        "# initialize a list to store reviews\n",
        "reviews = []\n",
        "\n",
        "# append each review\n",
        "for _, review in train_iter:\n",
        "    reviews.append(review)\n",
        "\n",
        "# initialize list to store tokenized reviews\n",
        "tokenized_reviews = []\n",
        "\n",
        "# preprocess and tokenize reviews\n",
        "for review in reviews:\n",
        "    lowercase_review = review.lower()\n",
        "    cleaned_review = re.sub(r'[^A-Za-z0-9\\s]+', '', lowercase_review.replace('<br />', ' '))\n",
        "    tokenized_reviews.append(word_tokenize(cleaned_review))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHwcY2uywmgG"
      },
      "source": [
        "## Markov (n-gram) Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBr3ybo6wmgH"
      },
      "source": [
        "A _Markov (n-gram)_ language model is a purely statistical character-level model. The model is based on the assumption that the probability of the next word in a sequence is based on the history _h_ of the preceding words in the sequence. For a set number _n_ of immediately previous words (or tokens) in the sequence, this assumption can be expressed as:\n",
        "\n",
        "$$P(w|h)\\approx P(w_n|w_{1:n-1})$$\n",
        "\n",
        "A _bigram_ is specific _n-gram_ case (_n_ = 2) where the conditional probability of the next word in a sequence is dependent solely on the preceding word in the sequence\n",
        "\n",
        "$$P(w|h)\\approx P(w_n|w_{n-1})$$\n",
        "\n",
        "We can further generalize this propoerty to _trigrams_ (_n_ = 3) such that the conditional probability of the next word in a sequence is\n",
        "\n",
        "$$P(w|h)\\approx P(w_n|w_{n-2, n-1})$$\n",
        "\n",
        "Let us create a general python class `build_random_ngram_model` that replicates the above funtionality with the IMBD dataset. In order to reduce recursive, repeating predicitons, the `predic()` method introduces randomness to the model, using a weighted choice between all tokens $w_n$ that correspond to a certain context $w_{1:n-1}$. The method parameter `rand` allows us to select the top `rand` weighted words from the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "id": "ahhLQCfKwmgH"
      },
      "outputs": [],
      "source": [
        "from nltk.util import ngrams\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "class build_random_ngram_model():\n",
        "\n",
        "    '''\n",
        "    This class builds a Markov (n-gram) language model.\n",
        "    '''\n",
        "    def __init__(self, tokenized_reviews: list, n: int = 2):\n",
        "        self.n = n\n",
        "        self.model = self._build_model(tokenized_reviews, n=n)\n",
        "\n",
        "    def _build_model(self, tokenized_reviews, n):\n",
        "\n",
        "        # empty return model\n",
        "        model = {}\n",
        "\n",
        "        # build model\n",
        "        print(\"builing model...\")\n",
        "        for review in tqdm(tokenized_reviews):\n",
        "\n",
        "            # build n-grams from reviews\n",
        "            for ngram in ngrams(review, n, pad_right=True, pad_left=True):\n",
        "                context = tuple(ngram[:-1])\n",
        "                target = ngram[-1]\n",
        "\n",
        "                # check if context is already in the model\n",
        "                if context not in model:\n",
        "                    model[context] = {}\n",
        "\n",
        "                # get frequency counts of co-occurrence\n",
        "                if target not in model[context]:\n",
        "                    model[context][target] = 1\n",
        "                else:\n",
        "                    model[context][target] += 1\n",
        "\n",
        "        # convert frequency counts to probabilities\n",
        "        for context in model:\n",
        "            count = float(sum(model[context].values()))\n",
        "            for target in model[context]:\n",
        "                model[context][target] /= count\n",
        "\n",
        "        # return trained model\n",
        "        print(\"done!\")\n",
        "        return model\n",
        "\n",
        "    def get_model(self) -> dict:\n",
        "\n",
        "        '''\n",
        "        Returns model stored as dict.\n",
        "        '''\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def predict(self, words: str, rand: int = None) -> str:\n",
        "\n",
        "        '''\n",
        "        This function returns the next word given the input string.\n",
        "        Randomly select out of the top rand probabilities given a certain context.\n",
        "        '''\n",
        "\n",
        "        # get last n-1 words in string\n",
        "        key = tuple(words.split())[1-self.n:]\n",
        "\n",
        "        # get top keys in dictionary\n",
        "        top_keys = sorted(self.model[key], key = self.model[key].get, reverse=True)[:rand]\n",
        "\n",
        "        # get probs of top keys\n",
        "        top_values = [self.model[key][top_key] for top_key in top_keys]\n",
        "\n",
        "        # select random key\n",
        "        selected_key = random.choices(top_keys, weights = top_values, k=1)[0]\n",
        "\n",
        "        return selected_key\n",
        "\n",
        "    def complete(self, words: str, rand: int = None) -> str:\n",
        "\n",
        "        '''\n",
        "        This function returns the entire string with the predicted next word\n",
        "        '''\n",
        "\n",
        "        next_word = self.predict(words, rand = rand)\n",
        "\n",
        "        # if context does not exist in model dict return original words\n",
        "        if next_word is not None:\n",
        "            completed_string = words+\" \"+next_word\n",
        "        else:\n",
        "            completed_string = words\n",
        "\n",
        "        return completed_string\n",
        "\n",
        "    def review(self, words: str, l = 10, rand: int = None) -> str:\n",
        "\n",
        "        '''\n",
        "        This function completes a review for an additional l words.\n",
        "        '''\n",
        "\n",
        "        working_words = words\n",
        "\n",
        "        i = 0\n",
        "\n",
        "        while i < l:\n",
        "            working_words = self.complete(working_words, rand = rand)\n",
        "            i += 1\n",
        "\n",
        "        return working_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WukicHnCwmgH"
      },
      "source": [
        "We can now build a trigram language model and generate random reviews from the input string `My favorite movie`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "cGKiwSHcwmgH",
        "outputId": "b515f47e-0c9e-405a-ca9d-6a5c308c7925"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-223-abcf2faf6538>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrigram_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_random_ngram_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_reviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrandom_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrigram_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"My favorite movie\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenized_reviews' is not defined"
          ]
        }
      ],
      "source": [
        "trigram_model = build_random_ngram_model(tokenized_reviews, 3)\n",
        "\n",
        "i = 0\n",
        "while i < 5:\n",
        "    random_review = trigram_model.review(\"My favorite movie\", 17)\n",
        "    print(random_review)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEbZAa21wmgH"
      },
      "source": [
        "## LSTM Based Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9tsMapywmgI"
      },
      "source": [
        "For the LSTM based language model we shall be following along with [Seq2Seq_LSTM_Simple_Sentiment_Analysis.ipynb](https://github.com/thejat/dl-notebooks/blob/master/examples/rnn/Seq2Seq_LSTM_Simple_Sentiment_Analysis.ipynb) and making modifications as neccessary.\n",
        "\n",
        "First we download the `\"train\"` and `\"test\"` splits from the `IMDB` dataset and check the size of each split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKXCW4ODwmgI",
        "outputId": "fe41c51e-78c8-4c0d-8e10-142d797718d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size:  25000\n",
            "Test dataset size:  25000\n"
          ]
        }
      ],
      "source": [
        "train_dataset_raw = datasets.IMDB(split=\"train\")\n",
        "test_dataset_raw = datasets.IMDB(split=\"test\")\n",
        "\n",
        "print(\"Train dataset size: \",len(list(train_dataset_raw)))\n",
        "print(\"Test dataset size: \",len(list(test_dataset_raw)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9kGMzkpwmgI"
      },
      "source": [
        "### Data Preprocessing Pipeline\n",
        "We next construct utilities to aid in the preprocessing of the `IMDB` dataset. Since we are creating a language model, our preprocessing pipeline must result in the generation of an _input sequence_ and _target sequence_. The _input sequence_ and _target sequence_ differ only by one \"time-step\".\n",
        "\n",
        "$$X_{Raw} =[x_1, x_2, \\ldots, x_T]$$\n",
        "$$X_{Input} = [x_1, x_2, \\ldots, x_{T-1}]$$\n",
        "$$X_{Target} = [x_2, x_3, \\ldots, x_{T}]$$\n",
        "\n",
        "The first utility is the `tokenizer()`, that parses through string instances in the datasets and converts to tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ShicIa1VwmgJ"
      },
      "outputs": [],
      "source": [
        "def tokenizer(text):\n",
        "    # step 1. remove HTML tags. they are not helpful in understanding the sentiments of a review\n",
        "    # step 2: use lowercase for all text to keep symmetry\n",
        "    # step 3: extract emoticons. keep them as they are important sentiment signals\n",
        "    # step 4: remove punctuation marks\n",
        "    # step 5: put back emoticons\n",
        "    # step 6: generate word tokens\n",
        "    text = re.sub(\"<[^>]*>\", \"\", text)\n",
        "    text = text.lower()\n",
        "    emoticons = re.findall(\"(?::|;|=)(?:-)?(?:\\)|\\(|D|P)\", text)\n",
        "    text = re.sub(\"[\\W]+\", \" \", text)\n",
        "    text = text + \" \".join(emoticons).replace(\"-\", \"\")\n",
        "    tokenized = text.split()\n",
        "    return tokenized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHrhjm2fwmgJ"
      },
      "source": [
        "We next create a utility to obtain `token_counts` from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKbTqwp5wmgJ",
        "outputId": "6cac656f-8709-4d4d-c82b-dfbcb2f76139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMDB train dataset vocab size: 75977\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "token_counts = Counter()\n",
        "\n",
        "for _, line in iter(train_dataset_raw):\n",
        "    tokens = tokenizer(line)\n",
        "    token_counts.update(tokens)\n",
        "\n",
        "print('IMDB train dataset vocab size:', len(token_counts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLsWbXdBwmgJ"
      },
      "source": [
        "The tokens are then sorted by frequency and converted to to integers using the `vocab` object. For the sake of computational complexity the first 500 words of the ordered dictionary by freqeuency are used for the model vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SFK-YFRwmgK",
        "outputId": "8c7aff00-9122-46d9-93ea-827af3803370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this  -->  11\n",
            "is  -->  7\n",
            "an  -->  35\n",
            "example  -->  462\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "\n",
        "reduced_ordered_dict = OrderedDict()\n",
        "\n",
        "count = 0\n",
        "for key, value in ordered_dict.items():\n",
        "    reduced_ordered_dict[key] = value\n",
        "    count += 1\n",
        "\n",
        "    if count == 1000:\n",
        "        break\n",
        "\n",
        "vb = vocab(reduced_ordered_dict)\n",
        "\n",
        "vb.insert_token(\"<pad>\", 0)  # special token for padding\n",
        "vb.insert_token(\"<unk>\", 1)  # special token for unknown words\n",
        "vb.set_default_index(1)\n",
        "\n",
        "# print some token indexes from vocab\n",
        "for token in [\"this\", \"is\", \"an\", \"example\"]:\n",
        "    print(token, \" --> \", vb[token])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7HL7e6twmgK"
      },
      "source": [
        "Inline lambda functions are then used for text processing. This is the first major deviation from the source code; to create _input sequences_ and _target sequences_ from the raw dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMli58Z4wmgK",
        "outputId": "6a7ccdbd-a3ab-46b9-c47a-4f675e006b96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Sequences\n",
            "Sample Tokens: ['i', 'rented', 'i', 'am', 'curious', 'yellow']\n",
            "Input Sequence: [10, 1, 10, 244, 1]\n",
            "Target Sequence: [1, 10, 244, 1, 1] \n",
            "\n",
            "Sample Tokens: ['i', 'am', 'curious', 'yellow', 'is', 'a']\n",
            "Input Sequence: [10, 244, 1, 1, 7]\n",
            "Target Sequence: [244, 1, 1, 7, 4] \n",
            "\n",
            "Sample Tokens: ['if', 'only', 'to', 'avoid', 'making', 'this']\n",
            "Input Sequence: [46, 64, 6, 789, 229]\n",
            "Target Sequence: [64, 6, 789, 229, 11] \n",
            "\n",
            "Sample Tokens: ['this', 'film', 'was', 'probably', 'inspired', 'by']\n",
            "Input Sequence: [11, 20, 14, 240, 1]\n",
            "Target Sequence: [20, 14, 240, 1, 34] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "input_pipeline = lambda x: [vb[token] for token in tokenizer(x)][:-1]\n",
        "target_pipline = lambda x: [vb[token] for token in tokenizer(x)][1:]\n",
        "\n",
        "length = 5\n",
        "print(\"Example Sequences\")\n",
        "for i in list(train_dataset_raw)[:4]:\n",
        "    example_tokens = tokenizer(i[1])[:length+1]\n",
        "    example_input = input_pipeline(i[1])[:length]\n",
        "    example_target = target_pipline(i[1])[:length]\n",
        "\n",
        "    print(f'Sample Tokens: {example_tokens}')\n",
        "    print(f'Input Sequence: {example_input}')\n",
        "    print(f'Target Sequence: {example_target}', \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejDoESUDwmgK"
      },
      "source": [
        "The preprocessing utilities will be applied at the batch level, as a `collate_fn` argument. The source code is modified to return the input and target sequences. Since these sequences are of the same length, we do not need to return length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "H0v862hHwmgK"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def collate_batch(batch):\n",
        "    input_list, target_list, = [], []\n",
        "\n",
        "    # iterate over all reviews in a batch\n",
        "    for _, _text in batch:\n",
        "\n",
        "        # input preprocessing\n",
        "        processed_input = torch.tensor(input_pipeline(_text), dtype=torch.int64)\n",
        "\n",
        "        # target preprocessing\n",
        "        processed_target = torch.tensor(input_pipeline(_text), dtype=torch.int64)\n",
        "\n",
        "\n",
        "        # store the processed text in input and target lists\n",
        "        input_list.append(processed_input)\n",
        "        target_list.append(processed_target)\n",
        "\n",
        "    # pad the processed reviews to make their lengths consistant\n",
        "    padded_input_list = nn.utils.rnn.pad_sequence(\n",
        "        input_list, batch_first=True)\n",
        "\n",
        "    padded_target_list = nn.utils.rnn.pad_sequence(\n",
        "        target_list, batch_first=True\n",
        "    )\n",
        "\n",
        "    # return\n",
        "    # 1. a list of processed and padded input texts\n",
        "    # 2. a list of processed and padded target texts\n",
        "    # 3. a list of review text original lengths (before padding)\n",
        "    return padded_input_list.to(device), padded_target_list.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1K4h4pKwmgK"
      },
      "source": [
        "### Batching the Training, Validation, and Test Datasets\n",
        "The `IMDB` Datasets are loaded into torch `DataLoader()` objects with the above `collate_batch()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "J39b4RWcwmgL"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset\n",
        "batch_size = 32\n",
        "\n",
        "train_dl = DataLoader(\n",
        "    train_dataset_raw, batch_size=batch_size, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "valid_dl = DataLoader(\n",
        "    test_dataset_raw, batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIGy9elVwmgL"
      },
      "source": [
        "### RNN Model Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmOSjaoDwmgL"
      },
      "source": [
        "We will now modify the source code's sentiment analysis `RNN` class for the purposes of language modeling. An overview of the architecture and design choices made to implement this are as follows:\n",
        "- An **Embedding layer** as as explained by the source code.\n",
        "- An **LSTM layer**  to capture long range dependencies and relationships in the text.\n",
        "- A **Fully Connected layer** to obtain `logits`, the raw unnormalized predictions for each token at each \"time step\" in the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JC4_rFTwmgL",
        "outputId": "a15c959c-967f-465d-916e-a44d4e101c99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 4124232\n"
          ]
        }
      ],
      "source": [
        "# create langauge model class\n",
        "class RNN_Language(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.rnn = nn.LSTM(embed_dim, vocab_size)#, batch_first=True)\n",
        "\n",
        "    def forward(self, input_sequence):\n",
        "        out = self.embedding(input_sequence)\n",
        "        out.size()\n",
        "        out, _ = self.rnn(out)\n",
        "        out.view(-1, vocab_size)\n",
        "        return out\n",
        "\n",
        "# instantiate a model\n",
        "vocab_size = len(vb)\n",
        "embed_dim = 20\n",
        "\n",
        "torch.manual_seed(576)\n",
        "model = RNN_Language(vocab_size, embed_dim)\n",
        "model = model.to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Number of parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUUITVWuwmgL"
      },
      "source": [
        "### Loss Function, Optimizer and Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRBt6owewmgM"
      },
      "source": [
        "We will utilize `CrossEntropyLoss()` as our loss function and the `Adam()` algorithm for optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZhU3s-mHwmgM"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "# training loop\n",
        "\n",
        "def train(model, train_dl, valid_dl):\n",
        "\n",
        "    train_history, valid_history = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        print(f\"Epopch: {epoch}\")\n",
        "\n",
        "        model.train()\n",
        "        total_loss, valid_loss = 0, 0\n",
        "\n",
        "        # training\n",
        "        for input_batch, target_batch in tqdm(train_dl):\n",
        "            with torch.set_grad_enabled(True):\n",
        "                # forward pass\n",
        "                optimizer.zero_grad()\n",
        "                logits = model(input_batch)\n",
        "                loss = criterion(logits.view(-1, vocab_size), target_batch.view(-1))\n",
        "\n",
        "                # backwards pass\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * batch_size\n",
        "\n",
        "        avg_loss = total_loss / 25_000\n",
        "        train_history.append(avg_loss)\n",
        "        print(f\"Training loss:\\t{avg_loss}\")\n",
        "\n",
        "        # validation\n",
        "        for input_batch, target_batch in valid_dl:\n",
        "            with torch.no_grad():\n",
        "                logits = model(input_batch)\n",
        "                loss = criterion(logits.view(-1, vocab_size), target_batch.view(-1))\n",
        "\n",
        "            valid_loss += loss.item() * batch_size\n",
        "\n",
        "        avg_valid_loss = valid_loss / 25_000\n",
        "        valid_history.append(valid_loss)\n",
        "        print(f\"Validation Loss\\t{avg_valid_loss}\\n\")\n",
        "\n",
        "\n",
        "    return train_history, valid_history\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "Mi3G7B6FwmgM",
        "outputId": "96eb859a-8738-46d7-dfd0-0c66a4bcda0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epopch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "393it [01:28,  4.42it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-868d2be963e2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-1fd05648ee88>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dl, valid_dl)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-888c30f00f9a>\u001b[0m in \u001b[0;36mcollate_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# target preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mprocessed_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-fa1be4d0247e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtarget_pipline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Example Sequences\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-fa1be4d0247e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtarget_pipline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Example Sequences\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_history, valid_history = train(model, train_dl, valid_dl)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size': 5})\n",
        "\n",
        "# plot loss history\n",
        "fig, ax = plt.subplots(figsize=(6,3.5), dpi=200)\n",
        "\n",
        "ax.plot(\n",
        "        train_history,\n",
        "        label = r'Training Loss',\n",
        "        #marker = 'o',\n",
        "        markersize = 4)\n",
        "\n",
        "ax.plot(\n",
        "        valid_history,\n",
        "        label = r'Validation loss',\n",
        "        #marker = 'o',\n",
        "        markersize = 4)\n",
        "\n",
        "ax.set_title(\"Model Loss History\")\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Model Loss')\n",
        "ax.set_xlim(1, len(train_history))\n",
        "ax.legend()\n",
        "ax.legend().get_frame().set_alpha(1.0)\n",
        "\n",
        "ax.grid(True)"
      ],
      "metadata": {
        "id": "MRZrtOA5WFL9",
        "outputId": "1d5ac33d-4511-4007-82bc-84a7a145733a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        }
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-233-f4f6290ccda5>:22: UserWarning: Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
            "  ax.set_xlim(1, len(train_history))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6CuxuxPwmgM"
      },
      "source": [
        "### Training and Evaluation Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def generate_text(model, text, max = 17, adjust = 1):\n",
        "    # set model to evaluation\n",
        "    model.eval()\n",
        "\n",
        "    # copy input string\n",
        "    input = text\n",
        "\n",
        "    # iterate max times\n",
        "    for _ in range(max):\n",
        "\n",
        "        # convert to tensor tokens\n",
        "        text_tokens = [vb[token] for token in tokenizer(input)]\n",
        "        tensor_tokens = torch.tensor(text_tokens, dtype = torch.int64).to(device)\n",
        "\n",
        "        # evaluate on model and adjust by scalar to add addtional randomness\n",
        "        with torch.no_grad():\n",
        "            logits = model(tensor_tokens)[-1,:] / adjust\n",
        "\n",
        "        # convert to probabilies\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        # use multinomial distribution to select index of next word based on probs\n",
        "        choice = torch.multinomial(probs, 1).item()\n",
        "\n",
        "        # obtain next word from vb\n",
        "        next_word = vb.lookup_token(choice)\n",
        "\n",
        "        # append to end of input string\n",
        "        input = input+\" \"+next_word\n",
        "\n",
        "    return input\n",
        "\n",
        "for i in range(5):\n",
        "    generated_text = generate_text(model, \"My favorite movie\", 17)\n",
        "    print(f\"Review {i+1}: {generated_text}\")"
      ],
      "metadata": {
        "id": "I8HS4PZ86DKo"
      },
      "execution_count": 220,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}